{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461dce9e",
   "metadata": {},
   "source": [
    "# Custom Cellpose Model Training for Brown Nuclei\n",
    "\n",
    "This notebook trains a custom Cellpose model using ImageJ ROI annotations.\n",
    "\n",
    "## Workflow:\n",
    "1. **Prepare Training Data**: Extract patches from ImageJ ROI positions\n",
    "2. **Optional Manual Refinement**: Edit masks in napari\n",
    "3. **Train Custom Model**: Fine-tune Cellpose on your data\n",
    "4. **Apply to Full Image**: Use trained model for segmentation\n",
    "\n",
    "## Prerequisites:\n",
    "- Mark nuclei in ImageJ (Multi-point tool or ROI Manager)\n",
    "- Save ROIs as .zip file: `Analyze > Tools > ROI Manager > More > Save`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c29d0a",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install read-roi cellpose napari scikit-learn scikit-image tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39982b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "from skimage import io, color\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.draw import disk\n",
    "import os\n",
    "import torch\n",
    "from cellpose import models, io as cellpose_io, train\n",
    "from read_roi import read_roi_file, read_roi_zip\n",
    "import napari\n",
    "\n",
    "# Check for GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {use_gpu}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c59659",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Training Data from ImageJ ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f899bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "IMAGE_PATH = r\"u:\\zyu\\Jupyter\\xinjian\\your_image.jpg\"  # Your HE image\n",
    "ROI_PATH = r\"u:\\zyu\\Jupyter\\xinjian\\RoiSet.zip\"      # ImageJ ROI file (.zip or .roi)\n",
    "OUTPUT_DIR = r\"u:\\zyu\\Jupyter\\xinjian\\training_data\" # Output directory\n",
    "CROP_SIZE = 64          # Size of training patches (64x64 or 128x128)\n",
    "NUCLEUS_RADIUS = 8      # Approximate nucleus radius in pixels\n",
    "TRAIN_TEST_SPLIT = 0.8  # 80% training, 20% testing\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Image: {IMAGE_PATH}\")\n",
    "print(f\"  ROIs: {ROI_PATH}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Crop Size: {CROP_SIZE}x{CROP_SIZE}\")\n",
    "print(f\"  Nucleus Radius: {NUCLEUS_RADIUS} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"test\"), exist_ok=True)\n",
    "\n",
    "print(f\"Created directories:\")\n",
    "print(f\"  {os.path.join(OUTPUT_DIR, 'train')}\")\n",
    "print(f\"  {os.path.join(OUTPUT_DIR, 'test')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8358a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img_rgb = io.imread(IMAGE_PATH)\n",
    "\n",
    "# Handle different image formats\n",
    "if img_rgb.ndim == 3 and img_rgb.shape[0] < 5:\n",
    "    img_rgb = np.transpose(img_rgb, (1, 2, 0))\n",
    "if img_rgb.shape[-1] == 4:\n",
    "    img_rgb = img_rgb[..., :3]\n",
    "\n",
    "print(f\"Loaded image: {img_rgb.shape} | dtype: {img_rgb.dtype}\")\n",
    "print(f\"Value range: [{img_rgb.min()}, {img_rgb.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ROIs from ImageJ\n",
    "if not os.path.exists(ROI_PATH):\n",
    "    raise FileNotFoundError(f\"ROI file not found: {ROI_PATH}\")\n",
    "\n",
    "if ROI_PATH.endswith('.zip'):\n",
    "    rois = read_roi_zip(ROI_PATH)\n",
    "else:\n",
    "    rois = read_roi_file(ROI_PATH)\n",
    "\n",
    "print(f\"Loaded {len(rois)} ROIs from ImageJ\")\n",
    "print(f\"ROI names: {list(rois.keys())[:5]}...\")  # Show first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942148e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nuclei positions from ROIs\n",
    "nuclei_positions = []\n",
    "\n",
    "for roi_name, roi_data in rois.items():\n",
    "    roi_type = roi_data.get('type', 'unknown')\n",
    "    \n",
    "    if roi_type == 'point':\n",
    "        # Point ROI (most common for Multi-point tool)\n",
    "        x = roi_data['x']\n",
    "        y = roi_data['y']\n",
    "        if isinstance(x, list):\n",
    "            for xi, yi in zip(x, y):\n",
    "                nuclei_positions.append((int(yi), int(xi)))  # (row, col)\n",
    "        else:\n",
    "            nuclei_positions.append((int(y), int(x)))\n",
    "    \n",
    "    elif roi_type in ['oval', 'rectangle']:\n",
    "        # Use center of shape\n",
    "        x = roi_data['left'] + roi_data['width'] / 2\n",
    "        y = roi_data['top'] + roi_data['height'] / 2\n",
    "        nuclei_positions.append((int(y), int(x)))\n",
    "    \n",
    "    elif roi_type in ['freehand', 'polygon', 'traced']:\n",
    "        # Use centroid of polygon\n",
    "        x = np.mean(roi_data['x'])\n",
    "        y = np.mean(roi_data['y'])\n",
    "        nuclei_positions.append((int(y), int(x)))\n",
    "    \n",
    "    else:\n",
    "        print(f\"Warning: Unsupported ROI type '{roi_type}' for {roi_name}\")\n",
    "\n",
    "print(f\"Extracted {len(nuclei_positions)} nuclei positions\")\n",
    "\n",
    "# Remove duplicates (same position)\n",
    "nuclei_positions = list(set(nuclei_positions))\n",
    "print(f\"After removing duplicates: {len(nuclei_positions)} unique positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop patches around each nucleus and create masks\n",
    "half_size = CROP_SIZE // 2\n",
    "cropped_images = []\n",
    "cropped_masks = []\n",
    "valid_positions = []\n",
    "\n",
    "for idx, (row, col) in enumerate(nuclei_positions):\n",
    "    # Define crop boundaries\n",
    "    r_min = row - half_size\n",
    "    r_max = row + half_size\n",
    "    c_min = col - half_size\n",
    "    c_max = col + half_size\n",
    "    \n",
    "    # Skip if too close to edge\n",
    "    if r_min < 0 or r_max > img_rgb.shape[0] or c_min < 0 or c_max > img_rgb.shape[1]:\n",
    "        continue\n",
    "    \n",
    "    # Crop image\n",
    "    crop = img_rgb[r_min:r_max, c_min:c_max, :].copy()\n",
    "    \n",
    "    # Create mask with nucleus at center\n",
    "    mask = np.zeros((CROP_SIZE, CROP_SIZE), dtype=np.uint16)\n",
    "    center_r = half_size\n",
    "    center_c = half_size\n",
    "    \n",
    "    # Create circular nucleus mask\n",
    "    rr, cc = disk((center_r, center_c), NUCLEUS_RADIUS, shape=(CROP_SIZE, CROP_SIZE))\n",
    "    mask[rr, cc] = 1  # Label ID = 1\n",
    "    \n",
    "    cropped_images.append(crop)\n",
    "    cropped_masks.append(mask)\n",
    "    valid_positions.append((row, col))\n",
    "\n",
    "print(f\"Generated {len(cropped_images)} valid training patches\")\n",
    "print(f\"Skipped {len(nuclei_positions) - len(cropped_images)} patches (too close to edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb9b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets\n",
    "n_train = int(TRAIN_TEST_SPLIT * len(cropped_images))\n",
    "n_test = len(cropped_images) - n_train\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.random.permutation(len(cropped_images))\n",
    "train_indices = indices[:n_train]\n",
    "test_indices = indices[n_train:]\n",
    "\n",
    "train_images = [cropped_images[i] for i in train_indices]\n",
    "train_masks = [cropped_masks[i] for i in train_indices]\n",
    "test_images = [cropped_images[i] for i in test_indices]\n",
    "test_masks = [cropped_masks[i] for i in test_indices]\n",
    "\n",
    "print(f\"Training set: {len(train_images)} patches\")\n",
    "print(f\"Test set: {len(test_images)} patches\")\n",
    "print(f\"Split ratio: {TRAIN_TEST_SPLIT*100:.0f}% / {(1-TRAIN_TEST_SPLIT)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data\n",
    "# Cellpose expects: image.tif and image_masks.tif\n",
    "\n",
    "for idx, (img, mask) in enumerate(zip(train_images, train_masks)):\n",
    "    tifffile.imwrite(\n",
    "        os.path.join(OUTPUT_DIR, \"train\", f\"nuclei_{idx:04d}.tif\"), \n",
    "        img\n",
    "    )\n",
    "    tifffile.imwrite(\n",
    "        os.path.join(OUTPUT_DIR, \"train\", f\"nuclei_{idx:04d}_masks.tif\"), \n",
    "        mask\n",
    "    )\n",
    "\n",
    "for idx, (img, mask) in enumerate(zip(test_images, test_masks)):\n",
    "    tifffile.imwrite(\n",
    "        os.path.join(OUTPUT_DIR, \"test\", f\"nuclei_{idx:04d}.tif\"), \n",
    "        img\n",
    "    )\n",
    "    tifffile.imwrite(\n",
    "        os.path.join(OUTPUT_DIR, \"test\", f\"nuclei_{idx:04d}_masks.tif\"), \n",
    "        mask\n",
    "    )\n",
    "\n",
    "print(f\"\\nSaved training data to: {OUTPUT_DIR}\")\n",
    "print(f\"  Train: {len(train_images)} image/mask pairs\")\n",
    "print(f\"  Test: {len(test_images)} image/mask pairs\")\n",
    "print(f\"\\nFile naming convention: nuclei_XXXX.tif and nuclei_XXXX_masks.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View samples in napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Show first 5 training examples\n",
    "n_show = min(5, len(train_images))\n",
    "for i in range(n_show):\n",
    "    viewer.add_image(train_images[i], name=f\"Train_{i}_Image\")\n",
    "    viewer.add_labels(train_masks[i], name=f\"Train_{i}_Mask\")\n",
    "\n",
    "print(f\"\\nOpened napari with {n_show} training examples\")\n",
    "print(\"Review the masks to ensure they are correct\")\n",
    "print(\"Close napari window to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f133cc",
   "metadata": {},
   "source": [
    "## Step 2: Manual Mask Refinement (Optional)\n",
    "\n",
    "If the circular masks are not accurate enough, you can manually refine them in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4076b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIONAL: Manually refine individual masks ---\n",
    "# Load specific image for editing\n",
    "\n",
    "EDIT_INDEX = 0  # Change this to edit different images\n",
    "\n",
    "edit_img = tifffile.imread(os.path.join(OUTPUT_DIR, \"train\", f\"nuclei_{EDIT_INDEX:04d}.tif\"))\n",
    "edit_mask = tifffile.imread(os.path.join(OUTPUT_DIR, \"train\", f\"nuclei_{EDIT_INDEX:04d}_masks.tif\"))\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(edit_img, name=\"Image\")\n",
    "labels_layer = viewer.add_labels(edit_mask, name=\"Mask (Editable)\")\n",
    "\n",
    "print(f\"\\nInstructions for manual editing:\")\n",
    "print(f\"1. Select the 'Mask (Editable)' layer\")\n",
    "print(f\"2. Use 'paint' tool to draw accurate nucleus boundaries\")\n",
    "print(f\"3. Use 'erase' tool to remove incorrect regions\")\n",
    "print(f\"4. Each nucleus should have label ID = 1\")\n",
    "print(f\"5. When done, execute the next cell to save\")\n",
    "print(f\"\\nEditing: nuclei_{EDIT_INDEX:04d}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37783966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edited mask\n",
    "if 'viewer' in locals() and viewer.layers:\n",
    "    edited_mask = viewer.layers['Mask (Editable)'].data\n",
    "    tifffile.imwrite(\n",
    "        os.path.join(OUTPUT_DIR, \"train\", f\"nuclei_{EDIT_INDEX:04d}_masks.tif\"), \n",
    "        edited_mask.astype(np.uint16)\n",
    "    )\n",
    "    print(f\"Saved edited mask for nuclei_{EDIT_INDEX:04d}\")\n",
    "    viewer.close()\n",
    "else:\n",
    "    print(\"No viewer found - run previous cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef96b5",
   "metadata": {},
   "source": [
    "## Step 3: Train Custom Cellpose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62995e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "MODEL_NAME = \"nuclei_brown_custom\"\n",
    "N_EPOCHS = 500           # More epochs = better performance (100-1000)\n",
    "LEARNING_RATE = 0.1      # Default is 0.1-0.2\n",
    "WEIGHT_DECAY = 0.0001    # Regularization\n",
    "BATCH_SIZE = 8           # Adjust based on GPU memory\n",
    "\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(OUTPUT_DIR, \"test\")\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Model Name: {MODEL_NAME}\")\n",
    "print(f\"  Epochs: {N_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  GPU: {use_gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data using Cellpose's loader\n",
    "output = cellpose_io.load_train_test_data(TRAIN_DIR, test_dir=TEST_DIR, mask_filter='_masks')\n",
    "train_images, train_labels, train_files, test_images, test_labels, test_files = output\n",
    "\n",
    "print(f\"\\nLoaded training data:\")\n",
    "print(f\"  Training images: {len(train_images)}\")\n",
    "print(f\"  Test images: {len(test_images)}\")\n",
    "print(f\"  Image shape: {train_images[0].shape}\")\n",
    "print(f\"  Mask shape: {train_labels[0].shape}\")\n",
    "print(f\"  Unique labels in first mask: {np.unique(train_labels[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model - start from pretrained 'nuclei' model for transfer learning\n",
    "model = models.CellposeModel(gpu=use_gpu, model_type='nuclei')\n",
    "\n",
    "print(f\"Initialized Cellpose model: nuclei (pretrained)\")\n",
    "print(f\"Starting training...\")\n",
    "print(f\"This may take 30 minutes to 2 hours depending on data size and GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Note: Training will print progress during execution\n",
    "\n",
    "model_path, train_losses, test_losses = model.train(\n",
    "    train_data=train_images,\n",
    "    train_labels=train_labels,\n",
    "    test_data=test_images,\n",
    "    test_labels=test_labels,\n",
    "    channels=[0, 0],          # Grayscale: [cytoplasm=0, nucleus=0]\n",
    "    save_path=OUTPUT_DIR,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    model_name=MODEL_NAME,\n",
    "    save_every=50             # Save checkpoint every 50 epochs\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final test loss: {test_losses[-1]:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1201307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training curves data\n",
    "import json\n",
    "\n",
    "training_info = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'n_epochs': N_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'n_train_images': len(train_images),\n",
    "    'n_test_images': len(test_images),\n",
    "    'model_path': model_path\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'training_info.json'), 'w') as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print(f\"Saved training info to: {os.path.join(OUTPUT_DIR, 'training_info.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad3ddf",
   "metadata": {},
   "source": [
    "## Step 4: Apply Trained Model to Full Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "MODEL_PATH = model_path  # From training, or specify path manually\n",
    "\n",
    "custom_model = models.CellposeModel(gpu=use_gpu, pretrained_model=MODEL_PATH)\n",
    "\n",
    "print(f\"Loaded custom model from: {MODEL_PATH}\")\n",
    "print(f\"Model diameter: {custom_model.diam_labels if hasattr(custom_model, 'diam_labels') else 'auto'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess full image for nuclei detection\n",
    "# Use color clustering to isolate brown nuclei\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Reshape for clustering\n",
    "pixels = img_rgb.reshape(-1, 3).astype(float)\n",
    "\n",
    "# K-means with 3 clusters: background, muscle, nuclei\n",
    "print(\"Performing K-means clustering to separate tissue components...\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(pixels)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# Identify clusters by intensity (darkest = nuclei)\n",
    "intensities = np.mean(cluster_centers, axis=1)\n",
    "background_label = np.argmax(intensities)  # Brightest\n",
    "nuclei_label = np.argmin(intensities)       # Darkest\n",
    "muscle_label = [i for i in range(3) if i not in [background_label, nuclei_label]][0]\n",
    "\n",
    "print(f\"\\nCluster Centers (RGB):\")\n",
    "print(f\"  Background (label {background_label}): {cluster_centers[background_label]}\")\n",
    "print(f\"  Muscle (label {muscle_label}): {cluster_centers[muscle_label]}\")\n",
    "print(f\"  Nuclei (label {nuclei_label}): {cluster_centers[nuclei_label]}\")\n",
    "\n",
    "# Create masks\n",
    "label_image = labels.reshape(img_rgb.shape[0], img_rgb.shape[1])\n",
    "nuclei_mask = (label_image == nuclei_label)\n",
    "background_mask = (label_image == background_label)\n",
    "\n",
    "print(f\"\\nPixel distribution:\")\n",
    "print(f\"  Background: {background_mask.sum()} ({100*background_mask.sum()/background_mask.size:.1f}%)\")\n",
    "print(f\"  Nuclei: {nuclei_mask.sum()} ({100*nuclei_mask.sum()/nuclei_mask.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ece93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nuclei channel for Cellpose\n",
    "# Convert to grayscale and invert so nuclei are bright on dark background\n",
    "\n",
    "nuclei_channel = rgb2gray(img_rgb)\n",
    "\n",
    "# Zero out background\n",
    "nuclei_channel[background_mask] = nuclei_channel.max()\n",
    "\n",
    "# Enhance nuclei regions\n",
    "nuclei_channel_enhanced = nuclei_channel.copy()\n",
    "nuclei_channel_enhanced[nuclei_mask] = nuclei_channel[nuclei_mask].min()\n",
    "\n",
    "# Invert: dark nuclei -> bright nuclei\n",
    "nuclei_norm = 1.0 - (nuclei_channel_enhanced - nuclei_channel_enhanced.min()) / (nuclei_channel_enhanced.max() - nuclei_channel_enhanced.min())\n",
    "\n",
    "# Convert to uint8\n",
    "nuclei_norm = (nuclei_norm * 255).astype(np.uint8)\n",
    "\n",
    "print(f\"Nuclei channel prepared:\")\n",
    "print(f\"  Shape: {nuclei_norm.shape}\")\n",
    "print(f\"  Range: [{nuclei_norm.min()}, {nuclei_norm.max()}]\")\n",
    "print(f\"  Mean: {nuclei_norm.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27853f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View preprocessing results in napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img_rgb, name=\"Original Image\", rgb=True)\n",
    "viewer.add_labels(label_image, name=\"K-means Clustering\")\n",
    "viewer.add_image(nuclei_norm, name=\"Nuclei Channel (for Cellpose)\", colormap='gray')\n",
    "\n",
    "print(\"Opened napari to review preprocessing\")\n",
    "print(\"Check if nuclei channel looks good before running Cellpose\")\n",
    "print(\"Close napari window to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f101fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom model on full image\n",
    "print(\"Running custom Cellpose model on full image...\")\n",
    "print(\"This may take several minutes depending on image size...\")\n",
    "\n",
    "masks_nuclei, flows, styles = custom_model.eval(\n",
    "    nuclei_norm,\n",
    "    diameter=None,              # Use diameter from training\n",
    "    channels=[0, 0],            # Grayscale\n",
    "    flow_threshold=0.4,         # Default: 0.4\n",
    "    cellprob_threshold=0.0,     # Default: 0.0\n",
    "    min_size=15                 # Minimum nucleus size in pixels\n",
    ")\n",
    "\n",
    "print(f\"\\nSegmentation complete!\")\n",
    "print(f\"Detected {masks_nuclei.max()} nuclei\")\n",
    "print(f\"Mask shape: {masks_nuclei.shape}\")\n",
    "print(f\"Mask dtype: {masks_nuclei.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_masks_path = os.path.join(OUTPUT_DIR, \"full_image_nuclei_masks.tif\")\n",
    "output_overlay_path = os.path.join(OUTPUT_DIR, \"full_image_nuclei_overlay.tif\")\n",
    "\n",
    "# Save masks\n",
    "tifffile.imwrite(output_masks_path, masks_nuclei.astype(np.uint16))\n",
    "\n",
    "print(f\"\\nSaved results:\")\n",
    "print(f\"  Masks: {output_masks_path}\")\n",
    "print(f\"  Total nuclei detected: {masks_nuclei.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc19858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final results in napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add layers\n",
    "viewer.add_image(img_rgb, name=\"Original Image\", rgb=True)\n",
    "viewer.add_image(nuclei_norm, name=\"Nuclei Channel\", colormap='gray', visible=False)\n",
    "viewer.add_labels(masks_nuclei, name=\"Nuclei Masks (Custom Model)\")\n",
    "\n",
    "print(f\"\\nOpened napari with final results\")\n",
    "print(f\"Detected {masks_nuclei.max()} nuclei using custom trained model\")\n",
    "print(f\"\\nTips:\")\n",
    "print(f\"  - Toggle layer visibility to compare\")\n",
    "print(f\"  - Adjust opacity of masks layer for better overlay view\")\n",
    "print(f\"  - Use 'pick' tool to inspect individual nucleus labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d1acc",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Model Performance (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "props = regionprops(masks_nuclei)\n",
    "\n",
    "areas = [p.area for p in props]\n",
    "eccentricities = [p.eccentricity for p in props]\n",
    "\n",
    "print(f\"\\nNuclei Statistics (n={len(props)}):\")\n",
    "print(f\"  Area (pixels):\")\n",
    "print(f\"    Mean: {np.mean(areas):.1f}\")\n",
    "print(f\"    Std: {np.std(areas):.1f}\")\n",
    "print(f\"    Min: {np.min(areas)}\")\n",
    "print(f\"    Max: {np.max(areas)}\")\n",
    "print(f\"  Eccentricity:\")\n",
    "print(f\"    Mean: {np.mean(eccentricities):.3f}\")\n",
    "print(f\"    Std: {np.std(eccentricities):.3f}\")\n",
    "\n",
    "# Store statistics\n",
    "nuclei_stats = {\n",
    "    'n_nuclei': len(props),\n",
    "    'area_mean': float(np.mean(areas)),\n",
    "    'area_std': float(np.std(areas)),\n",
    "    'eccentricity_mean': float(np.mean(eccentricities)),\n",
    "    'eccentricity_std': float(np.std(eccentricities))\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'nuclei_statistics.json'), 'w') as f:\n",
    "    json.dump(nuclei_stats, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved statistics to: {os.path.join(OUTPUT_DIR, 'nuclei_statistics.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d91faf",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training complete! Key outputs:\n",
    "\n",
    "1. **Trained Model**: `{OUTPUT_DIR}/{MODEL_NAME}`\n",
    "2. **Nuclei Masks**: `{OUTPUT_DIR}/full_image_nuclei_masks.tif`\n",
    "3. **Training Info**: `{OUTPUT_DIR}/training_info.json`\n",
    "4. **Statistics**: `{OUTPUT_DIR}/nuclei_statistics.json`\n",
    "\n",
    "### Next Steps:\n",
    "- If results are not satisfactory, add more annotations and retrain\n",
    "- Adjust `flow_threshold` and `cellprob_threshold` in eval() for fine-tuning\n",
    "- Use this model on other similar images\n",
    "- Combine with muscle cell segmentation for quantification"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
